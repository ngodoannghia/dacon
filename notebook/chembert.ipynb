{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\crawl\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at E://competition//atoms//ChemBERTa-77M-MTR and are newly initialized: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"E://competition//atoms//ChemBERTa-77M-MTR\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"E://competition//atoms//ChemBERTa-77M-MTR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Molecule ChEMBL ID</th>\n",
       "      <th>Standard Type</th>\n",
       "      <th>Standard Relation</th>\n",
       "      <th>Standard Value</th>\n",
       "      <th>Standard Units</th>\n",
       "      <th>pChEMBL Value</th>\n",
       "      <th>Assay ChEMBL ID</th>\n",
       "      <th>Target ChEMBL ID</th>\n",
       "      <th>Target Name</th>\n",
       "      <th>Target Organism</th>\n",
       "      <th>Target Type</th>\n",
       "      <th>Document ChEMBL ID</th>\n",
       "      <th>IC50_nM</th>\n",
       "      <th>pIC50</th>\n",
       "      <th>Smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL4443947</td>\n",
       "      <td>IC50</td>\n",
       "      <td>'='</td>\n",
       "      <td>0.022</td>\n",
       "      <td>nM</td>\n",
       "      <td>10.66</td>\n",
       "      <td>CHEMBL4361896</td>\n",
       "      <td>CHEMBL3778</td>\n",
       "      <td>Interleukin-1 receptor-associated kinase 4</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>SINGLE PROTEIN</td>\n",
       "      <td>CHEMBL4359855</td>\n",
       "      <td>0.022</td>\n",
       "      <td>10.66</td>\n",
       "      <td>CN[C@@H](C)C(=O)N[C@H](C(=O)N1C[C@@H](NC(=O)CC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL4556091</td>\n",
       "      <td>IC50</td>\n",
       "      <td>'='</td>\n",
       "      <td>0.026</td>\n",
       "      <td>nM</td>\n",
       "      <td>10.59</td>\n",
       "      <td>CHEMBL4345131</td>\n",
       "      <td>CHEMBL3778</td>\n",
       "      <td>Interleukin-1 receptor-associated kinase 4</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>SINGLE PROTEIN</td>\n",
       "      <td>CHEMBL4342485</td>\n",
       "      <td>0.026</td>\n",
       "      <td>10.59</td>\n",
       "      <td>CC(C)(O)[C@H](F)CN1Cc2cc(NC(=O)c3cnn4cccnc34)c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL4566431</td>\n",
       "      <td>IC50</td>\n",
       "      <td>'='</td>\n",
       "      <td>0.078</td>\n",
       "      <td>nM</td>\n",
       "      <td>10.11</td>\n",
       "      <td>CHEMBL4345131</td>\n",
       "      <td>CHEMBL3778</td>\n",
       "      <td>Interleukin-1 receptor-associated kinase 4</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>SINGLE PROTEIN</td>\n",
       "      <td>CHEMBL4342485</td>\n",
       "      <td>0.078</td>\n",
       "      <td>10.11</td>\n",
       "      <td>CC(C)(O)[C@H](F)CN1Cc2cc(NC(=O)c3cnn4cccnc34)c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL4545898</td>\n",
       "      <td>IC50</td>\n",
       "      <td>'='</td>\n",
       "      <td>0.081</td>\n",
       "      <td>nM</td>\n",
       "      <td>10.09</td>\n",
       "      <td>CHEMBL4345131</td>\n",
       "      <td>CHEMBL3778</td>\n",
       "      <td>Interleukin-1 receptor-associated kinase 4</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>SINGLE PROTEIN</td>\n",
       "      <td>CHEMBL4342485</td>\n",
       "      <td>0.081</td>\n",
       "      <td>10.09</td>\n",
       "      <td>CC(C)(O)[C@H](F)CN1Cc2cc(NC(=O)c3cnn4cccnc34)c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL4448950</td>\n",
       "      <td>IC50</td>\n",
       "      <td>'='</td>\n",
       "      <td>0.099</td>\n",
       "      <td>nM</td>\n",
       "      <td>10.00</td>\n",
       "      <td>CHEMBL4361896</td>\n",
       "      <td>CHEMBL3778</td>\n",
       "      <td>Interleukin-1 receptor-associated kinase 4</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>SINGLE PROTEIN</td>\n",
       "      <td>CHEMBL4359855</td>\n",
       "      <td>0.099</td>\n",
       "      <td>10.00</td>\n",
       "      <td>COc1cc2c(OC[C@@H]3CCC(=O)N3)ncc(C#CCCCCCCCCCCC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Molecule ChEMBL ID Standard Type Standard Relation  Standard Value  \\\n",
       "0      CHEMBL4443947          IC50               '='           0.022   \n",
       "1      CHEMBL4556091          IC50               '='           0.026   \n",
       "2      CHEMBL4566431          IC50               '='           0.078   \n",
       "3      CHEMBL4545898          IC50               '='           0.081   \n",
       "4      CHEMBL4448950          IC50               '='           0.099   \n",
       "\n",
       "  Standard Units  pChEMBL Value Assay ChEMBL ID Target ChEMBL ID  \\\n",
       "0             nM          10.66   CHEMBL4361896       CHEMBL3778   \n",
       "1             nM          10.59   CHEMBL4345131       CHEMBL3778   \n",
       "2             nM          10.11   CHEMBL4345131       CHEMBL3778   \n",
       "3             nM          10.09   CHEMBL4345131       CHEMBL3778   \n",
       "4             nM          10.00   CHEMBL4361896       CHEMBL3778   \n",
       "\n",
       "                                  Target Name Target Organism     Target Type  \\\n",
       "0  Interleukin-1 receptor-associated kinase 4    Homo sapiens  SINGLE PROTEIN   \n",
       "1  Interleukin-1 receptor-associated kinase 4    Homo sapiens  SINGLE PROTEIN   \n",
       "2  Interleukin-1 receptor-associated kinase 4    Homo sapiens  SINGLE PROTEIN   \n",
       "3  Interleukin-1 receptor-associated kinase 4    Homo sapiens  SINGLE PROTEIN   \n",
       "4  Interleukin-1 receptor-associated kinase 4    Homo sapiens  SINGLE PROTEIN   \n",
       "\n",
       "  Document ChEMBL ID  IC50_nM  pIC50  \\\n",
       "0      CHEMBL4359855    0.022  10.66   \n",
       "1      CHEMBL4342485    0.026  10.59   \n",
       "2      CHEMBL4342485    0.078  10.11   \n",
       "3      CHEMBL4342485    0.081  10.09   \n",
       "4      CHEMBL4359855    0.099  10.00   \n",
       "\n",
       "                                              Smiles  \n",
       "0  CN[C@@H](C)C(=O)N[C@H](C(=O)N1C[C@@H](NC(=O)CC...  \n",
       "1  CC(C)(O)[C@H](F)CN1Cc2cc(NC(=O)c3cnn4cccnc34)c...  \n",
       "2  CC(C)(O)[C@H](F)CN1Cc2cc(NC(=O)c3cnn4cccnc34)c...  \n",
       "3  CC(C)(O)[C@H](F)CN1Cc2cc(NC(=O)c3cnn4cccnc34)c...  \n",
       "4  COc1cc2c(OC[C@@H]3CCC(=O)N3)ncc(C#CCCCCCCCCCCC...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([data_train['Molecule ChEMBL ID'], data_train['Smiles']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Molecule ChEMBL ID</th>\n",
       "      <th>Smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL4443947</td>\n",
       "      <td>CN[C@@H](C)C(=O)N[C@H](C(=O)N1C[C@@H](NC(=O)CC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL4556091</td>\n",
       "      <td>CC(C)(O)[C@H](F)CN1Cc2cc(NC(=O)c3cnn4cccnc34)c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL4566431</td>\n",
       "      <td>CC(C)(O)[C@H](F)CN1Cc2cc(NC(=O)c3cnn4cccnc34)c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL4545898</td>\n",
       "      <td>CC(C)(O)[C@H](F)CN1Cc2cc(NC(=O)c3cnn4cccnc34)c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL4448950</td>\n",
       "      <td>COc1cc2c(OC[C@@H]3CCC(=O)N3)ncc(C#CCCCCCCCCCCC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Molecule ChEMBL ID                                             Smiles\n",
       "0      CHEMBL4443947  CN[C@@H](C)C(=O)N[C@H](C(=O)N1C[C@@H](NC(=O)CC...\n",
       "1      CHEMBL4556091  CC(C)(O)[C@H](F)CN1Cc2cc(NC(=O)c3cnn4cccnc34)c...\n",
       "2      CHEMBL4566431  CC(C)(O)[C@H](F)CN1Cc2cc(NC(=O)c3cnn4cccnc34)c...\n",
       "3      CHEMBL4545898  CC(C)(O)[C@H](F)CN1Cc2cc(NC(=O)c3cnn4cccnc34)c...\n",
       "4      CHEMBL4448950  COc1cc2c(OC[C@@H]3CCC(=O)N3)ncc(C#CCCCCCCCCCCC..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CN[C@@H](C)C(=O)N[C@H](C(=O)N1C[C@@H](NC(=O)CCOCCOCCOCC#Cc2cnc(OC[C@@H]3CCC(=O)N3)c3cc(OC)c(C(N)=O)cc23)C[C@H]1C(=O)N[C@@H]1CCCc2ccccc21)C1CCCCC1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_smile = train['Smiles'][0]\n",
    "test_smile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = train['Smiles'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT TEXT MUST BE ALREADY WORD-SEGMENTED!\n",
    "sentence = 'Chúng_tôi là những nghiên_cứu_viên .'  \n",
    "\n",
    "input_ids = torch.tensor([tokenizer.encode(test_smile, max_length=256, truncation=True)])\n",
    "\n",
    "with torch.no_grad():\n",
    "    features = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 112])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor([tokenizer.encode(smiles[4], max_length=256, truncation=True)])\n",
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n"
     ]
    }
   ],
   "source": [
    "max_len = -1\n",
    "for s in smiles:\n",
    "    input_ids = torch.tensor([tokenizer.encode(s)])\n",
    "    \n",
    "    size = input_ids.shape[1]\n",
    "    if size > max_len:\n",
    "        print(size)\n",
    "        max_len = size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 119, 384])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[-2.0801, -1.5884, -2.7264,  ..., -0.8330, -2.2768, -3.9664],\n",
       "         [-2.0189, -1.8411, -1.1740,  ..., -0.8589, -3.1837, -3.6122],\n",
       "         [-1.5233, -1.9519, -1.5481,  ..., -1.4673, -1.9218, -1.9707],\n",
       "         ...,\n",
       "         [-2.1487, -2.0737, -2.8245,  ..., -1.9424, -2.2815, -3.8734],\n",
       "         [-2.7176, -2.2366, -3.3407,  ..., -2.7212, -1.4406, -2.9181],\n",
       "         [-2.5865, -1.8417, -2.0097,  ..., -1.0150, -2.0509, -3.7648]]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([767])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(features[0], 1).reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(AttentionPooling, self).__init__()\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, outputs):\n",
    "        weights = torch.softmax(self.attention(outputs), dim=1)\n",
    "        context_vector = torch.sum(weights * outputs, dim=1)\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = AttentionPooling(hidden_size=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 600])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention(features[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\crawl\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at E://competition//atoms//ChemBERTa-77M-MTR and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"E://competition//atoms//ChemBERTa-77M-MTR\")\n",
    "model = AutoModel.from_pretrained(\"E://competition//atoms//ChemBERTa-77M-MTR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode_plus(\n",
    "            test_smile,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=64,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=False,\n",
    "            truncation=True)\n",
    "input_ids = torch.tensor(inputs['input_ids'], dtype=torch.long)\n",
    "attention_mask = torch.tensor(inputs['attention_mask'], dtype=torch.long)\n",
    "with torch.no_grad():\n",
    "    features = model(input_ids=input_ids.unsqueeze(0), attention_mask=attention_mask.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 384])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
